{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nW2jHWNBBBZz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "\n",
        "import folium\n",
        "from folium.plugins import HeatMap\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z8wsKOABBZ0"
      },
      "source": [
        "## **This notebook analyzes the following variables: Conductor Material, Type, Age, and Work Order Date**\n",
        "\n",
        "Uses the same base as 'living_life_code.ipynb' by Judy\n",
        "\n",
        "## 1. Preprocess the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6sgWvNvBBZ1"
      },
      "outputs": [],
      "source": [
        "# vri_df = pd.read_csv('data/src_vri_snapshot_2024_03_20.csv')\n",
        "span_df = pd.read_csv('data/dev_wings_agg_span_2024_01_01.csv')\n",
        "gis_2024_1004 = pd.read_csv('data/gis_weatherstation_shape_2024_10_04.csv')\n",
        "station_summary_2023_08_02 = pd.read_csv('data/src_wings_meteorology_station_summary_snapshot_2023_08_02.csv')\n",
        "windspeed_2023_08_02 = pd.read_csv('data/src_wings_meteorology_windspeed_snapshot_2023_08_02.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "tbRMEhpNBBZ1",
        "outputId": "13a55de8-73c4-4f22-bef7-aa7472d1d8fd"
      },
      "outputs": [],
      "source": [
        "merged_df = pd.merge(station_summary_2023_08_02, gis_2024_1004, right_on= 'weatherstationcode', left_on='station', how='left')\n",
        "merged_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "jrSGByvxBBZ1",
        "outputId": "10f6e887-dab0-4fcc-b43d-d671a76cae70"
      },
      "outputs": [],
      "source": [
        "windspeed_grouped_count = windspeed_2023_08_02.groupby(by='station').count()\n",
        "windspeed_grouped_count.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmXWuaqBBBZ1"
      },
      "outputs": [],
      "source": [
        "station_codes = np.array(gis_2024_1004['weatherstationcode'])\n",
        "merged_station_df = gis_2024_1004.merge(station_summary_2023_08_02, left_on='weatherstationcode', right_on='station', how='left')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDIQk5PSBBZ2"
      },
      "outputs": [],
      "source": [
        "merged_df[merged_df['weatherstationcode']=='AMO']['alert'].iloc[0]\n",
        "\n",
        "prob_lst = []\n",
        "\n",
        "for station in station_codes:\n",
        "    station_windspeeds = np.array(windspeed_2023_08_02[windspeed_2023_08_02['station'] == station]['wind_speed'])\n",
        "    # \"alert\" might be nan because of less entries in station_ss_df\n",
        "    has_threshold = True\n",
        "    try:\n",
        "        threshold = merged_df[merged_df['weatherstationcode'] == station]['alert'].iloc[0]\n",
        "    except:\n",
        "        has_threshold = False\n",
        "        prob = np.nan\n",
        "    mean = np.nanmean(station_windspeeds)\n",
        "    if has_threshold:\n",
        "        prob = np.mean([1 if x >= threshold else 0 for x in station_windspeeds]) * 100\n",
        "    count = np.count_nonzero(~np.isnan(station_windspeeds))\n",
        "    prob_lst.append([station, station_windspeeds, threshold, count, mean, prob])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "Qc0NCG0-BBZ2",
        "outputId": "60a461b9-c419-4502-d693-5d8c7f80b217"
      },
      "outputs": [],
      "source": [
        "prob_df = pd.DataFrame(prob_lst)\n",
        "prob_df.columns = ['station', 'windspeeds', 'threshold', 'count', 'mean', 'probability (%)']\n",
        "prob_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nelvmqj9BBZ2"
      },
      "outputs": [],
      "source": [
        "gis_2024_1004['shape'] = gpd.GeoSeries.from_wkt(gis_2024_1004['shape'])\n",
        "gis_gdf = gpd.GeoDataFrame(gis_2024_1004, geometry='shape').set_crs(epsg=4431).to_crs(epsg=4326)\n",
        "\n",
        "# vri_df['shape'] = gpd.GeoSeries.from_wkt(vri_df['shape'])\n",
        "# vri_gdf = gpd.GeoDataFrame(vri_df, geometry='shape').set_crs(epsg=4326)\n",
        "\n",
        "span_df['shape'] = gpd.GeoSeries.from_wkt(span_df['shape'])\n",
        "span_gdf = gpd.GeoDataFrame(span_df, geometry='shape').set_crs(epsg=2230).to_crs(epsg=4326)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AegeS85-BBZ2"
      },
      "outputs": [],
      "source": [
        "gis_gdf = gis_gdf.drop(columns=['shape_srid'])\n",
        "# vri_gdf = vri_gdf.drop(columns=['shape_srid'])\n",
        "span_gdf = span_gdf.drop(columns=['shape_srid'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dgfnnr9TBBZ3"
      },
      "outputs": [],
      "source": [
        "# gis_vri_merge = gis_gdf.merge(vri_gdf, left_on='weatherstationcode', right_on='anemometercode')\n",
        "# vri_gdf['centroid'] = vri_gdf['shape'].centroid\n",
        "# vri_gis_sjoin = vri_gdf.sjoin(gis_gdf, how='inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "id": "Z0fVu5A_BBZ3",
        "outputId": "43364f2d-4352-4d7b-e9ac-dc12e22c6235"
      },
      "outputs": [],
      "source": [
        "prob_merge = gis_gdf.merge(prob_df, left_on='weatherstationcode', right_on='station').merge(station_summary_2023_08_02, left_on='weatherstationcode', right_on='station')\n",
        "prob_merge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmGN6DwDBBZ3"
      },
      "outputs": [],
      "source": [
        "# vri_mapping = {'H': 2, 'M': 1, 'L': 0}\n",
        "# prob_merge['vri_numeric'] = prob_merge['vri'].map(vri_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "DB1ThOpXBBZ3",
        "outputId": "1838df0e-c072-447d-8f01-baa4a1c62a62"
      },
      "outputs": [],
      "source": [
        "# prob_merge.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rtVTIlzyBBZ3",
        "outputId": "b592c380-4947-40e8-e4e6-061155d27d04"
      },
      "outputs": [],
      "source": [
        "span_df_cleaned = span_df.dropna(subset=['station'])\n",
        "span_prob_merge_df = prob_merge.merge(span_df_cleaned, left_on='weatherstationcode', right_on='station')\n",
        "span_prob_merge_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuV80o5qBBZ4",
        "outputId": "e8085949-0bbd-4404-d01b-180b8bc104c1"
      },
      "outputs": [],
      "source": [
        "print(list(span_prob_merge_df.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5pSPFE1BBZ4",
        "outputId": "45f32081-8d43-4e10-8c42-451022f83026"
      },
      "outputs": [],
      "source": [
        "columns_to_keep = [\n",
        "    'probability (%)',\n",
        "    'hardened_state', 'miles', \n",
        "    'upstream_struct_age', 'upstream_struct_hftd', 'upstream_struct_material', 'upstream_struct_type', 'upstream_struct_workorderdate',\n",
        "    'downstream_struct_age', 'downstream_struct_hftd', 'downstream_struct_material', 'downstream_struct_type', 'downstream_struct_workorderdate',\n",
        "    'wire_risk',\n",
        "]\n",
        "\n",
        "df_filtered = span_prob_merge_df[columns_to_keep]\n",
        "\n",
        "# columns_to_impute = ['num_strike_trees', 'buffered_tree_counts', 'exclusive_tree_counts']\n",
        "# for col in columns_to_impute:\n",
        "#     min_val, max_val = df_filtered[col].min(), df_filtered[col].max()\n",
        "#     df_filtered[col] = df_filtered[col].apply(\n",
        "#         lambda x: np.random.randint(min_val, max_val + 1) if pd.isna(x) else x\n",
        "#     )\n",
        "\n",
        "df_filtered.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fix 'workorderdate' datatype from str to datetime\n",
        "df_filtered['upstream_struct_workorderdate'] = df_filtered['upstream_struct_workorderdate'].replace('NaN',np.nan)\n",
        "df_filtered['downstream_struct_workorderdate'] = df_filtered['downstream_struct_workorderdate'].replace('NaN',np.nan)\n",
        "\n",
        "df_filtered['upstream_struct_workorderdate'] = pd.to_datetime(df_filtered['upstream_struct_workorderdate'],format='%Y-%m-%d')\n",
        "df_filtered['downstream_struct_workorderdate'] = pd.to_datetime(df_filtered['downstream_struct_workorderdate'],format='%Y-%m-%d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# calculate the days past since the last work order\n",
        "upstream_workorder_days = pd.Timestamp.now() - df_filtered['upstream_struct_workorderdate']\n",
        "df_filtered['days_since_upstream_workorder'] = [i.days for i in upstream_workorder_days]\n",
        "downstream_workorder_days = pd.Timestamp.now() - df_filtered['downstream_struct_workorderdate']\n",
        "df_filtered['days_since_downstream_workorder'] = [i.days for i in downstream_workorder_days]\n",
        "\n",
        "# drop original columns\n",
        "df_filtered = df_filtered.drop(columns=['upstream_struct_workorderdate', 'downstream_struct_workorderdate'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# one-hot encoding\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "categorical_columns = ['hardened_state', 'wire_risk',\n",
        "                       'upstream_struct_type', 'downstream_struct_type', 'downstream_struct_material', 'upstream_struct_material']\n",
        "one_hot_encoded = encoder.fit_transform(df_filtered[categorical_columns])\n",
        "one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(categorical_columns))\n",
        "\n",
        "df_encoded = pd.concat([df_filtered.drop(categorical_columns, axis=1), one_hot_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_encoded.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRdQN1DNBBZ4"
      },
      "source": [
        "## 2. EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "Bwl7HyuKBBZ4",
        "outputId": "3d97c091-712c-4c23-9f8c-fc19ff2e8943"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(df_filtered['probability (%)'], bins=30, kde=True, color='blue')\n",
        "plt.title(\"Distribution of Wildfire Probability (%)\")\n",
        "plt.xlabel(\"Probability (%)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.barplot(data=df_filtered, x='upstream_struct_type', y='probability (%)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.barplot(data=df_filtered, x='downstream_struct_type', y='probability (%)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sorted_material = df_filtered['upstream_struct_material'].unique()\n",
        "sorted_material"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.barplot(data=df_filtered, x='upstream_struct_material', y='probability (%)', order=sorted_material)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.barplot(data=df_filtered, x='downstream_struct_material', y='probability (%)', order=sorted_material)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "sorted_type = df_filtered['upstream_struct_type'].unique()\n",
        "sorted_material = df_filtered['upstream_struct_material'].unique()\n",
        "\n",
        "sns.barplot(data=df_filtered, x='upstream_struct_type', y='probability (%)', order=sorted_type, ax=axes[0, 0], color='blue')\n",
        "axes[0, 0].set_title(\"Upstream Structure Type vs Wildfire Probability\")\n",
        "\n",
        "sns.barplot(data=df_filtered, x='downstream_struct_type', y='probability (%)', order=sorted_type, ax=axes[1, 0], color='red')\n",
        "axes[1, 0].set_title(\"Downstream Struct Type vs Wildfire Probability\")\n",
        "\n",
        "sns.barplot(data=df_filtered, x='upstream_struct_material', y='probability (%)', order=sorted_material, ax=axes[0, 1], color='blue')\n",
        "axes[0, 1].set_title(\"Upstream Structure Material vs Wildfire Probability\")\n",
        "\n",
        "sns.barplot(data=df_filtered, x='downstream_struct_material', y='probability (%)', order=sorted_material, ax=axes[1, 1], color='red')\n",
        "axes[1, 1].set_title(\"Downstream Struct Material vs Wildfire Probability\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Tvrr58qaBBZ5",
        "outputId": "134c0123-b629-41f3-f9aa-72deec41d728"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "sns.scatterplot(data=df_filtered, x='wire_risk', y='probability (%)', ax=axes[0, 0], color='orange')\n",
        "axes[0, 0].set_title(\"Wire Risk vs Wildfire Probability\")\n",
        "\n",
        "sns.scatterplot(data=df_filtered, x='upstream_struct_age', y='probability (%)', ax=axes[0, 1], color='blue')\n",
        "axes[0, 1].set_title(\"Upstream Struct Age vs Wildfire Probability\")\n",
        "\n",
        "sns.scatterplot(data=df_filtered, x='miles', y='probability (%)', ax=axes[1, 0], color='green')\n",
        "axes[1, 0].set_title(\"Miles vs Wildfire Probability\")\n",
        "\n",
        "sns.scatterplot(data=df_filtered, x='downstream_struct_age', y='probability (%)', ax=axes[1, 1], color='red')\n",
        "axes[1, 1].set_title(\"Downstream Struct Age vs Wildfire Probability\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-Lftu9lBBZ5"
      },
      "source": [
        "## 3. ML models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bU7KSiVmBBZ5"
      },
      "outputs": [],
      "source": [
        "# columns_to_impute = ['num_strike_trees', 'buffered_tree_counts', 'exclusive_tree_counts']\n",
        "# for col in columns_to_impute:\n",
        "#     min_val, max_val = df_encoded[col].min(), df_encoded[col].max()\n",
        "#     df_encoded[col] = df_encoded[col].apply(\n",
        "#         lambda x: np.random.randint(min_val, max_val + 1) if pd.isna(x) else x\n",
        "#     )\n",
        "\n",
        "X = df_encoded.drop(columns=['probability (%)'])\n",
        "y = df_encoded['probability (%)']\n",
        "\n",
        "imputer = SimpleImputer(strategy=\"mean\")\n",
        "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "7W5eQs-cBBZ6",
        "outputId": "a159f254-01e1-4b67-b59c-1d817653cfdd"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Random Forest\": RandomForestRegressor(n_estimators=100, max_depth=25, random_state=30),\n",
        "    # \"Support Vector Regressor\": SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1),\n",
        "    # \"MLP Regressor\": MLPRegressor(hidden_layer_sizes=(50, 50), learning_rate_init=0.01, max_iter=300, random_state=42)\n",
        "}\n",
        "\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    if name in [\"Random Forest\", \"Linear Regression\"]:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "    else:\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    results.append({\"Model\": name, \"MAE\": mae, \"MSE\": mse, \"R² Score\": r2})\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# best max_depth\n",
        "results = []\n",
        "for i in np.arange(1, 50, 5):\n",
        "    rf_model = RandomForestRegressor(n_estimators=100, max_depth=i, random_state=30)\n",
        "    rf_model.fit(X_train_scaled, y_train)\n",
        "    y_pred = rf_model.predict(X_test_scaled)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    results.append({\"MAE\": mae, \"MSE\": mse, \"R² Score\": r2})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame(results)\n",
        "results_df['max depth'] = np.arange(1, 50, 5)\n",
        "results_df = results_df[['max depth', 'MAE', 'MSE', 'R² Score']]\n",
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# best random_state\n",
        "results = []\n",
        "for i in np.arange(1, 50, 5):\n",
        "    rf_model = RandomForestRegressor(n_estimators=100, max_depth=45, random_state=i)\n",
        "    rf_model.fit(X_train_scaled, y_train)\n",
        "    y_pred = rf_model.predict(X_test_scaled)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    results.append({\"MAE\": mae, \"MSE\": mse, \"R² Score\": r2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame(results)\n",
        "results_df['random state'] = np.arange(1, 50, 5)\n",
        "results_df = results_df[['random state', 'MAE', 'MSE', 'R² Score']]\n",
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
        "\n",
        "# Define model\n",
        "model = RandomForestRegressor()\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [10, 50, 100],  \n",
        "    'max_depth': [None, 10, 20],  \n",
        "    'min_samples_split': [2, 5, 10]  \n",
        "}\n",
        "\n",
        "# Set up k-fold cross-validation\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform Grid Search with Cross-Validation\n",
        "grid_search = GridSearchCV(model, param_grid, cv=kfold, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Evaluate on test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Calculate RMSE (Root Mean Squared Error)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)  # Compute R² score\n",
        "\n",
        "print(\"Test RMSE:\", rmse)\n",
        "print(\"Test R² Score:\", r2)\n",
        "\n",
        "# Best Parameters: {'max_depth': 20, 'min_samples_split': 10, 'n_estimators': 100}\n",
        "# Test RMSE: 3.130248996295386\n",
        "# Test R² Score: 0.535236624009354"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf_model = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=5, min_samples_split=10)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f'MAE: {mae}, MSE: {mse}, R2 score: {r2}')\n",
        "\n",
        "# MAE: 1.498273167365387, MSE: 9.764269329112558, R2 score: 0.5368583080336017"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get feature importances\n",
        "feature_names = np.array(X.columns)\n",
        "importances = rf_model.feature_importances_\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=importances, y=feature_names, palette=\"viridis\")\n",
        "plt.xlabel(\"Feature Importance Score\")\n",
        "plt.ylabel(\"Features\")\n",
        "plt.title(\"Feature Importance in Random Forest Regression\")\n",
        "# plt.yticks(np.arange(0, 36, step=1.1))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import plot_tree\n",
        "\n",
        "# Plot one of the trees from the forest\n",
        "plt.figure(figsize=(20,10))\n",
        "plot_tree(rf_model.estimators_[0], feature_names=feature_names, filled=True, max_depth=3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tree = rf_model.estimators_[0]  # 0 for the first tree, you can change this index\n",
        "# Inspecting the internal tree structure\n",
        "tree_ = tree.tree_\n",
        "\n",
        "# Display the feature names and decision thresholds for the first 5 nodes\n",
        "for i in range(5):\n",
        "    print(f\"Node {i}:\")\n",
        "    print(f\"  Feature: {feature_names[tree_.feature[i]] if tree_.feature[i] != -2 else 'Leaf'}\")\n",
        "    print(f\"  Threshold: {tree_.threshold[i]}\")\n",
        "    print(f\"  Samples: {tree_.n_node_samples[i]}\")\n",
        "    print(f\"  Value: {tree_.value[i]}\")\n",
        "    print(\"----\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIqSN6CYBBZ6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
