{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading and Loading Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To lessen the work of clicking individual files to download, we use BeautifulSoup to scrape the filenames from the website.\n",
    "\n",
    "Parent directory: https://sdge.sdsc.edu/data/sdge/\n",
    "\n",
    "**Note:** Right now we have only downloaded files from 2020-08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Fetch the web page\n",
    "url = \"https://sdge.sdsc.edu/data/sdge/ens_gfs_001/2020-08/\"\n",
    "response = requests.get(url)\n",
    "data = response.text\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(data, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The files/filenames are organized in a table\n",
    "# Extract them from the table\n",
    "fns = []\n",
    "for tr in soup.find('table').find_all('tr'):\n",
    "    # print(tr)\n",
    "    row = [url.text for url in tr.find_all('a')]\n",
    "    fns.append(row[1])\n",
    "\n",
    "# first 2 elements are not filenames\n",
    "fns = fns[2:]\n",
    "fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the download urls, which are basically parent directory + filename\n",
    "# Files will be downloaded to the local \"data\" folder\n",
    "urls = []\n",
    "dest = []\n",
    "for i in fns:\n",
    "    temp = 'https://sdge.sdsc.edu/data/sdge/ens_gfs_001/2020-08/' + i\n",
    "    urls.append(temp)\n",
    "\n",
    "    temp = 'data/' + i\n",
    "    dest.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following 2 code cell downloads the files from an online website, do not run unless needed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from multiprocessing import cpu_count\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "# Normal loop that downloads files from urls\n",
    "# args is a zip of urls and destinations\n",
    "def download_url(args):\n",
    "    t0 = time.time()\n",
    "    url, fn = args[0], args[1]\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        with open(fn, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        return(url, time.time() - t0)\n",
    "    except Exception as e:\n",
    "        print('Exception in download_url():', e)\n",
    "\n",
    "# Download multiple files in parallel \n",
    "def download_parallel(args):\n",
    "    cpus = cpu_count()\n",
    "    results = ThreadPool(cpus - 1).imap_unordered(download_url, args)\n",
    "    # prints results of downloaded file and time taken\n",
    "    for result in results:\n",
    "        print('url:', result[0], 'time (s):', result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the download code\n",
    "inputs = zip(urls, dest)\n",
    "download_parallel(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the .nc files downloaded, we open them using the xarray library.\n",
    "\n",
    ".nc files have metadata, which is retained when opened as datasets. However, converting them into Pandas dataframes loses that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dest has all the file paths\n",
    "dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test: open one dataset\n",
    "ds = xr.open_dataset(dest[0])\n",
    "\n",
    "# Print variable names\n",
    "print(ds.data_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting ds to df\n",
    "df = ds.to_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some messy first look at the data, using that one ds we loaded ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.data_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
